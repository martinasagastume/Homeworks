# -*- coding: utf-8 -*-
"""HW_Transformer martina (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LhvXAq3-LP_n89xfcKKigPmrRye4iQqU

#TRANSFORMERS

In this notebook we will see different applications of transformers.</br>
Transformers are a type of deep learning architecture introduced in the paper "Attention is All You Need"  (2017) by Vaswani et al. They revolutionized natural language processing (NLP) and other domains by enabling models to efficiently process sequential data, such as text, while capturing long-range dependencies and relationships between elements.</br>
At their core, transformers rely on the self-attention mechanism , which allows the model to dynamically weigh the importance of different parts of the input sequence. This makes them highly scalable, parallelizable, and capable of handling complex tasks.</br>
From a technical point of view the architecture of transformers has two main components: the encoder, able to convert plain text in rich contextualized embeddings and the decoder, with complementary capabilities. </br>
This notebook will show different applications of transformers. A really short travel given their extraordinary capabilities, not only for language but for other kind of non structured data.

IMPORTANT NOTICES:

1. In most of this notebook we will use the Huggingface models and the corresponding libraries to implement our snippets.
The use of Huggingface requires a TOKEN that can be obtained in the HF site after a FREE registration and left in the "secrets" repository of the Google Colab instance (see left side menu).</br>
The following is the authentication process.

2. Switch Runtime architecture from CPU to T4 GPU (*Upper menu -> Runtime -> Change Runtime Type -> T4 GPU -> Save*).  And then, restart the session. (*Upper menu -> Runtime -> Restart Session*)

2. Many examples below need to load and run a model and can take some time. **Be patient**.
"""

import os

# Lee el token desde los secrets
token = os.environ.get("HUGGINGFACE_TOKEN")

# Inicia sesiÃ³n con el token
from huggingface_hub import login
login(token)

!pip install huggingface_hub
from huggingface_hub import login
from google.colab import userdata

#HF_TOKEN = userdata.get('HF_TOKEN')
HF_TOKEN = "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"
if not HF_TOKEN:
    raise ValueError("ðŸ¤– Please add your Hugging Face token to Colab Secrets as 'HF_TOKEN'")
login(token=HF_TOKEN, add_to_git_credential=False)

"""Load the required modules"""

from transformers import pipeline
import pandas as pd

"""We will use the following texts to test the different capabilities of transformers</br>
They are both mails received from the same customer (Walter White). First one is a complaint and the second one is a gratefulness mail after the problem was properly managed by the company.
"""

complaint = "Dear ACME Customer Service Team," \
           "I hope this email finds you well. I am writing to formally complain " \
           "about an issue with my recent purchase.\n" \
           "Last month, I purchased an HappySummer Plus Motorhome (Order #1234567890), " \
           "which was received on last Friday, 1 of March. However, upon first tests, " \
           "I discovered that the vehicle received was a HappySummer basic model, which does " \
           "not match what I ordered.\n" \
           "This discrepancy has caused me significant inconvenience because the " \
           "delivered model is not compatible with my existing car accessories and it " \
           "lacks the microwave oven I specifically needed for my cooking.\n" \
           "To resolve this issue, I kindly request:\n" \
           "- Immediate replacement with the correct model HappySummer Plus as " \
           "originally ordered, or\n" \
           "A full refund if the correct model is unavailable.\n" \
           "I have attached the proof of purchase (receipt) and some photos " \
           "of the delivered product. Please confirm your resolution plan by " \
           "this week. I trust ACME will address this matter promptly to " \
           "maintain your reputation for excellent customer service.\n" \
           "My best regards\n" \
           "Walter White"

congrats = "Dear [Customer Service Manager's Name or Team],\n" \
           "I hope this message finds you well. I am writing to express my " \
           "sincere gratitude for the prompt and effective resolution of my recent" \
           "complaint regarding the incorrect delivery of my Motorhome HappySummer Plus.\n" \
           "Thanks to your teamâ€™s quick action, I received the correct vehicle on Tuesday, " \
           "and it works perfectly. I truly appreciate your professionalism and dedication to " \
           "customer satisfaction.\n" \
           "Special thanks to Hank Schrader for their exceptional assistance â€”your responsiveness " \
           "turned a frustrating situation into a positive experience. ACMEâ€™s commitment to " \
           "resolving issues efficiently reaffirms my trust in your brand.\n" \
           "I look forward to continuing as a loyal customer and will not hesitate " \
           "to recommend ACME to others.\n" \
           "My best regards\n" \
           "Walter White"

emails = [complaint, congrats]

"""## CLASSIFICATION
Transformers classify text by processing the input sequence and producing a fixed-size representation that captures the overall meaning of the text. This representation is then passed through a **classification head** (feed forward + softmax/sigmoid) to predict the class label. The process involves encoding the input text, extracting meaningful features, and mapping those features to class probabilities.</br>
Only the ENCODER is necessary for the classification tasks.</br>
Even that our model is flexible, we will use it as is and will only have a binary result based on the text of the mail: positive or negative.
"""

classifier = pipeline("text-classification")

classification = []
for email in emails:
  classification.append(classifier(email))
pd.DataFrame(classification)

"""##NAMED ENTITIES RECOGNITION (NER)
Transformers  can effectively identify Named Entities (NE)  in text. NER involves detecting and classifying entities (e.g., names of people, organizations, locations, dates, etc.) in a given text.
To perform NER using transformers, the encoder-only  architecture is typically used, as the task involves understanding and encoding input text rather than generating new sequences.
NER is indirectly a classification task: Each token in the input sequence is classified into one of several predefined categories (e.g., PERSON, LOCATION, ORGANIZATION, DATE, etc.).    
"""

ner_tagger = pipeline("ner", aggregation_strategy="simple")

ner = []
for email in emails:
  results = ner_tagger(email)
  for result in results:
    ner.append(result)
pd.DataFrame(ner)

"""##QUESTION & ANSWER

Q&A can also be solved with Transformers.QA involves understanding a question and finding the most relevant answer within a provided context or passage. Transformers excel at this task due to their ability to capture deep contextual relationships in text.</br>
There are two main types of question-answering tasks:
*   Extractive Question Answering: The model identifies and extracts the exact span of text from the input that answers the question.
*   Abstractive Question Answering: The model generates a free-form answer by paraphrasing or synthesizing information from the input.</br>
The components of the transformer architecture involved depend on the type of QA task, but in our case, we will use Extractive Q&A, so only the Encoder part will be involved.
"""

reader = pipeline("question-answering")
questions = ["What did the customer complain about?", "What is the name of the customer?", "Which product the email is related to?"]

for question in questions:
  print(f"Q:{question}")
  answer = reader(question = question, context = complaint)
  print(f"A:{answer['answer']}")

"""##SUMMARIZING
Finally we will see how transformers are highly effective for text summarization  tasks. They can condense a long input text into a shorter, more concise version while retaining the key information. As in the Q&A task, there are two main approaches to summarization:
*   Extractive Summarization : The model selects important sentences or phrases directly from the input text.
*   Abstractive Summarization : The model generates a summary by paraphrasing and synthesizing information from the input text.
     
In our example we will use abstractive summarization with the input emails. So decoder will generate a reduced version of the embeddings produced by the encoder.
"""

# Initialize abstractive summarization pipeline (encoder-decoder)
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

for i, email in enumerate(emails):
  summary = summarizer(email, max_length = 100, min_length = 20, do_sample = False)
  ner.append(result)
  print(f"\nAbstractive Summary[{i}]:{summary[0]['summary_text']}")

"""#ACTIVITY

The following is a free text about University of arround 500 words.
In **two separated cells**:
1. Generate a summary of less than 100 words
2. Find the answers to the following questions:
*  What are the main challenges that students face in University life?
*  What do some of students discover in Univeristy?
*  Which living habits can adopt the students to decrease monetary pressures?

"""

life_university = """ University is often the first time young adults experience true independence. Moving away from home means taking charge of daily responsibilities, from managing finances to maintaining a healthy lifestyle. While this newfound freedom is exhilarating, it also comes with its share of challenges. Balancing coursework, part-time jobs, and personal commitments requires discipline and adaptability.
Living independently teaches valuable life skills that extend far beyond the classroom. Budgeting becomes crucial as students learn to stretch limited resources while prioritizing essentials. Cooking meals, doing laundry, and keeping living spaces tidy may seem mundane, but mastering these tasks instills a sense of accomplishment and self-reliance. Navigating bureaucratic processes like registering for classes, applying for scholarships, or resolving housing issues further sharpens organizational abilities.
Emotional maturity is another key aspect of personal development during university. Being away from family support systems forces students to confront challenges head-on and develop resilience. Homesickness, stress, and uncertainty are common emotions that arise, but overcoming them builds inner strength and emotional intelligence. Counseling services and peer support networks offered by universities provide valuable assistance during tough times, reminding students that they are never alone.
Self-discovery is perhaps the most profound outcome of university life. Removed from familiar surroundings, students have the freedom to explore who they are and who they want to become. They experiment with new hobbies, adopt fresh perspectives, and redefine their values. Some discover hidden talents; others find clarity about their career aspirations. This period of introspection lays the groundwork for future decisions and aspirations.
Challenges and Coping Strategies
Despite its many rewards, university life is not without its difficulties. Academic pressure, financial constraints, and mental health struggles are realities faced by countless students. Recognizing these challenges and adopting effective coping strategies is essential for thriving in this environment.
Academic stress is perhaps the most pervasive issue. The sheer volume of material to cover, coupled with high expectations, can overwhelm even the most diligent students. To combat this, time management techniques such as creating schedules, setting priorities, and breaking tasks into manageable chunks prove invaluable. Seeking help from professors, teaching assistants, or tutoring centers is also encouraged, as these resources are designed to support student success.
Financial burdens pose another significant hurdle. Tuition fees, accommodation costs, textbooks, and other expenses can strain budgets, especially for those relying on loans or part-time jobs. Scholarships, grants, and budgeting apps offer practical solutions, while frugal living habitsâ€”like cooking at home or opting for second-hand textbooksâ€”can ease monetary pressures. Universities often provide financial literacy workshops and emergency funds to assist students in need.
Mental health concerns, including anxiety, depression, and burnout, are increasingly prevalent among university students. The stigma surrounding mental health has diminished in recent years, thanks to awareness campaigns and advocacy efforts. Counseling centers, mindfulness workshops, and peer support groups create safe spaces for addressing emotional struggles. Practicing self-care through exercise, meditation, or creative outlets also contributes to overall well-being.
Balancing academics with social and personal commitments presents yet another challenge. Overcommitting to extracurricular activities or neglecting rest can lead to burnout. Setting boundaries, saying no when necessary, and scheduling downtime are crucial for maintaining equilibrium. Learning to prioritize what truly matters helps students stay focused and fulfilled.
Lifelong Lessons and Future Prospects
The lessons learned during university transcend academic knowledge. Time management, adaptability, and resilience are just a few examples of skills that prepare students for life beyond graduation. These competencies empower graduates to navigate the complexities of the modern workforce, pursue advanced studies, or embark on entrepreneurial ventures.
Networking plays a vital role in shaping future prospects. Connections made during universityâ€”whether with professors, alumni, or fellow studentsâ€”can open doors to internships, job opportunities, and mentorship programs. Career fairs, industry panels, and alumni events facilitate these interactions, enabling students to build professional relationships that last a lifetime.
Perhaps the greatest legacy of university life is the sense of possibility it instills. Graduates leave equipped not only with diplomas but also with confidence, vision, and a hunger for continuous learning. Whether pursuing careers in medicine, engineering, arts, or business, they carry forward the spirit of inquiry and innovation nurtured during their university years.
In conclusion, life in university is a multifaceted experience that encompasses academics, social dynamics, independence, and personal growth. It is a crucible where challenges are met with determination, friendships are forged, and dreams take flight. Though fraught with obstacles, this journey equips individuals with the tools and mindset needed to thrive in an ever-evolving world. As students graduate and move on to the next phase of their lives, they carry with them the indelible imprint of their university experienceâ€”a testament to the power of education to transform lives. """

# Initialize abstractive summarization pipeline (encoder-decoder)
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

for i, life_university in enumerate(emails):
  summary = summarizer(life_university, max_length = 100, min_length = 20, do_sample = False)
  ner.append(result)
  print(f"\nAbstractive Summary[{i}]:{summary[0]['summary_text']}")

# Initialize abstractive summarization pipeline (encoder-decoder)
#I would use the abstractive summary in this code
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

for i, life_university in enumerate(emails):
  summary = summarizer(life_university, max_length = 100, min_length = 20, do_sample = False)
  ner.append(result)
  print(f"\nAbstractive Summary[{i}]:{summary[0]['summary_text']}")

# Initialize abstractive summarization pipeline (encoder-decoder)
# I would use the extractive summary in this code
for i, life_university in enumerate(life_university):
  summary = summarizer(life_university, max_length = 100, min_length = 10, do_sample = False)
  ner.append(result)
  print(f"\nExtractive Summary[{i}]:{summary[0]['summary_text']}")

"""Question and answering"""

reader = pipeline("question-answering")
questions = ["What are the main challenges that students face in University life?", "What do some of students discover in Univeristy?", "Which living habits can adopt the students to decrease monetary pressures?"]

for question in questions:
  print(f"Q:{question}")
  answer = reader(question = question, context = life_university)
  print(f"A:{answer['answer']}")